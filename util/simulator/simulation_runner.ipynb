{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambulance Redeployment Simulation Runner\n",
    "\n",
    "Use this notebook to execute the SimPy-based simulator across every redeployment rule and compare key KPIs (response time, coverage, utilization, queue length)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data note\n",
    "\n",
    "This folder does not include simulated incident JSON datasets (for example: `day.json`, `week.json`). Only the prompt scripts (`prompt.sh`) are kept under `resources/simulated_records/`.\n",
    "\n",
    "To run simulations, pass incident-history files using `history_paths=...` in `run_rules(...)` / `SimulationRunner.run(...)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_repo_root() -> Path:\n",
    "    \"\"\"Find the repo root (expects `util/` next to `resources/`).\"\"\"\n",
    "    base = Path.cwd().resolve()\n",
    "    for candidate in (base,) + tuple(base.parents):\n",
    "        util_dir = candidate / \"util\"\n",
    "        resources_dir = candidate / \"resources\"\n",
    "        if util_dir.is_dir() and resources_dir.is_dir():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Unable to locate repo root (expected util/ and resources/).\");\n",
    "\n",
    "\n",
    "REPO_ROOT = _resolve_repo_root()\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Iterable, Sequence\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from util.simulator.rules import RuleCatalog\n",
    "from util.simulator.simulator import SimulationRunner\n",
    "\n",
    "\n",
    "catalog = RuleCatalog()\n",
    "runner = SimulationRunner()\n",
    "\n",
    "ALL_RULE_IDS = tuple(catalog.ids())\n",
    "DEFAULT_TEMPLATE = \"day\"\n",
    "SIM_DATA_ROOT = REPO_ROOT / \"resources\" / \"simulated_records\"\n",
    "\n",
    "def run_rules(\n",
    "    rule_ids: Iterable[str] | None = None,\n",
    "    *,\n",
    "    template: str = DEFAULT_TEMPLATE,\n",
    "    seed: int = 0,\n",
    "    history_paths: Iterable[str | Path] | None = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Run the simulator for every rule and return summary + unit-level metrics.\"\"\"\n",
    "\n",
    "    ids = tuple(rule_ids) if rule_ids else ALL_RULE_IDS\n",
    "    rows = []\n",
    "    unit_rows = []\n",
    "    for idx, rule_id in enumerate(ids, start=1):\n",
    "        result = runner.run(\n",
    "            rule_id,\n",
    "            template,\n",
    "            seed=seed + idx,\n",
    "            history_paths=history_paths,\n",
    "        )\n",
    "        row = {\"rule\": rule_id, **result.metrics}\n",
    "        row[\"seed\"] = seed + idx\n",
    "        row[\"template\"] = template\n",
    "        rows.append(row)\n",
    "        for unit_entry in result.unit_utilization:\n",
    "            unit_rows.append({\"rule\": rule_id, **unit_entry})\n",
    "    summary_df = (\n",
    "        pd.DataFrame(rows).set_index(\"rule\").sort_values(\"average_response_minutes\")\n",
    "    )\n",
    "    unit_df = pd.DataFrame(unit_rows)\n",
    "    return summary_df, unit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE_BUNDLES: dict[str, Sequence[str]] = {\n",
    "}\n",
    "\n",
    "\n",
    "def _paths(*names: str) -> list[Path]:\n",
    "    return [SIM_DATA_ROOT / name for name in names]\n",
    "\n",
    "\n",
    "SCENARIO_LIBRARY: dict[str, dict] = {\n",
    "    \"baseline_day\": {\n",
    "        \"template\": \"day\",\n",
    "        \"bundle\": \"simple\",\n",
    "        \"paths\": _paths(\"baseline/day.json\"),\n",
    "        \"notes\": \"1-day FCFS benchmark\",\n",
    "    },\n",
    "    \"baseline_week\": {\n",
    "        \"template\": \"week\",\n",
    "        \"bundle\": \"simple\",\n",
    "        \"paths\": _paths(\"baseline/week.json\"),\n",
    "        \"notes\": \"7-day FCFS reference\",\n",
    "    },\n",
    "    \"baseline_month\": {\n",
    "        \"template\": \"month\",\n",
    "        \"bundle\": \"simple\",\n",
    "        \"paths\": _paths(\"baseline/month.json\"),\n",
    "        \"notes\": \"30-day FCFS reference\",\n",
    "    },\n",
    "    \"intermediate_day\": {\n",
    "        \"template\": \"day\",\n",
    "        \"bundle\": \"peak\",\n",
    "        \"paths\": _paths(\"intermediate/day.json\"),\n",
    "        \"notes\": \"Dense day with multiple urban peaks\",\n",
    "    },\n",
    "    \"intermediate_week\": {\n",
    "        \"template\": \"week\",\n",
    "        \"bundle\": \"peak\",\n",
    "        \"paths\": _paths(\"intermediate/week.json\"),\n",
    "        \"notes\": \"Urban-heavy week scenario\",\n",
    "    },\n",
    "    \"intermediate_month\": {\n",
    "        \"template\": \"month\",\n",
    "        \"bundle\": \"peak\",\n",
    "        \"paths\": _paths(\"intermediate/month.json\"),\n",
    "        \"notes\": \"30-day mixed peaks\",\n",
    "    },\n",
    "    \"stress_day\": {\n",
    "        \"template\": \"day\",\n",
    "        \"bundle\": \"perfect\",\n",
    "        \"paths\": _paths(\"stress/day.json\"),\n",
    "        \"notes\": \"High-demand stress test\",\n",
    "    },\n",
    "    \"stress_week\": {\n",
    "        \"template\": \"week\",\n",
    "        \"bundle\": \"perfect\",\n",
    "        \"paths\": _paths(\"stress/week.json\"),\n",
    "        \"notes\": \"Aggressive peak redeploy workload\",\n",
    "    },\n",
    "    \"stress_month\": {\n",
    "        \"template\": \"month\",\n",
    "        \"bundle\": \"perfect\",\n",
    "        \"paths\": _paths(\"stress/month.json\"),\n",
    "        \"notes\": \"Extreme redeploy workload\",\n",
    "    },\n",
    "    \"lightweight_day\": {\n",
    "        \"template\": \"day\",\n",
    "        \"bundle\": \"perfect\",\n",
    "        \"paths\": _paths(\"lightweight/day.json\"),\n",
    "        \"notes\": \"Lean day aiming for sub-15 min responses\",\n",
    "    },\n",
    "    \"lightweight_week\": {\n",
    "        \"template\": \"week\",\n",
    "        \"bundle\": \"perfect\",\n",
    "        \"paths\": _paths(\"lightweight/week.json\"),\n",
    "        \"notes\": \"Lean week scenario\",\n",
    "    },\n",
    "    \"lightweight_month\": {\n",
    "        \"template\": \"month\",\n",
    "        \"bundle\": \"perfect\",\n",
    "        \"paths\": _paths(\"lightweight/month.json\"),\n",
    "        \"notes\": \"Lean month scenario\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def run_scenario(\n",
    "    scenario_name: str,\n",
    "    *,\n",
    "    seed: int = 100,\n",
    "    rule_ids: Sequence[str] | None = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    config = SCENARIO_LIBRARY[scenario_name]\n",
    "    selected_rules = rule_ids or config.get(\"rule_ids\")\n",
    "    if selected_rules is None:\n",
    "        bundle = config.get(\"bundle\")\n",
    "        selected_rules = RULE_BUNDLES.get(bundle, ALL_RULE_IDS)\n",
    "    return run_rules(\n",
    "        rule_ids=selected_rules,\n",
    "        template=config.get(\"template\", DEFAULT_TEMPLATE),\n",
    "        seed=seed,\n",
    "        history_paths=config.get(\"paths\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df, unit_df = run_scenario(\"baseline_day\", seed=100)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = summary_df.sort_values(\"average_response_minutes\").plot(\n",
    "    kind=\"bar\",\n",
    "    y=[\"average_response_minutes\", \"coverage_ratio\"],\n",
    "    secondary_y=\"coverage_ratio\",\n",
    "    figsize=(12, 6),\n",
    "    title=\"Response Time vs Coverage by Rule\",\n",
    ")\n",
    "ax.set_ylabel(\"Average Response (minutes)\")\n",
    "ax.right_ax.set_ylabel(\"Coverage ratio\")\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_utilization_heatmap(unit_df: pd.DataFrame, top_n: int = 10):\n",
    "    if unit_df.empty:\n",
    "        print(\"No unit-level data available.\")\n",
    "        return\n",
    "    pivot = (\n",
    "        unit_df.groupby([\"rule\", \"home_base_id\"])  # aggregate per base\n",
    "        [\"busy_ratio\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .pivot(index=\"rule\", columns=\"home_base_id\", values=\"busy_ratio\")\n",
    "    )\n",
    "    pivot = pivot.fillna(0).sort_index()\n",
    "    ax = pivot.iloc[:, :top_n].plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        figsize=(14, 6),\n",
    "        title=\"Unit Utilization Contribution per Rule\",\n",
    "    )\n",
    "    ax.set_ylabel(\"Busy ratio (fraction of horizon)\")\n",
    "    ax.legend(title=\"Home Base\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "    return ax\n",
    "\n",
    "# plot_utilization_heatmap(unit_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare demand profiles\n",
    "Use this section to run the same rule set against multiple incident-history files (e.g., `sim_day_peak1pm.json` vs `sim_week_peak1pm.json`) and visualize the metrics side by side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_history_profiles(\n",
    "    profiles: dict[str, dict],\n",
    "    *,\n",
    "    default_template: str = DEFAULT_TEMPLATE,\n",
    "    seed: int = 500,\n",
    "    rule_ids: Iterable[str] | None = None,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Run `run_rules` for each profile definition and concatenate metrics.\"\"\"\n",
    "\n",
    "    frames: list[pd.DataFrame] = []\n",
    "    unit_frames: list[pd.DataFrame] = []\n",
    "    for label, config in profiles.items():\n",
    "        profile_template = config.get(\"template\", default_template)\n",
    "        profile_rules = config.get(\"rule_ids\")\n",
    "        bundle = config.get(\"bundle\")\n",
    "        selected_rules = profile_rules or (\n",
    "            RULE_BUNDLES.get(bundle) if bundle else rule_ids\n",
    "        )\n",
    "        paths = [\n",
    "            SIM_DATA_ROOT / Path(path)\n",
    "            if not isinstance(path, Path)\n",
    "            else path\n",
    "            for path in config.get(\"paths\", [])\n",
    "        ]\n",
    "        summary_df, unit_df = run_rules(\n",
    "            rule_ids=selected_rules,\n",
    "            template=profile_template,\n",
    "            seed=seed,\n",
    "            history_paths=paths,\n",
    "        )\n",
    "        summary_df = summary_df.reset_index()\n",
    "        summary_df[\"profile\"] = label\n",
    "        unit_df = unit_df.copy()\n",
    "        unit_df[\"profile\"] = label\n",
    "        frames.append(summary_df)\n",
    "        unit_frames.append(unit_df)\n",
    "        seed += config.get(\"seed_step\", 17)\n",
    "    combined = pd.concat(frames, ignore_index=True)\n",
    "    combined_unit = pd.concat(unit_frames, ignore_index=True)\n",
    "    return combined, combined_unit\n",
    "\n",
    "\n",
    "history_profiles = {\n",
    "    \"Baseline day\": {\n",
    "        \"paths\": _paths(\"baseline/day.json\"),\n",
    "        \"template\": \"day\",\n",
    "        \"bundle\": \"simple\",\n",
    "    },\n",
    "    \"Intermediate week\": {\n",
    "        \"paths\": _paths(\"intermediate/week.json\"),\n",
    "        \"template\": \"week\",\n",
    "        \"bundle\": \"peak\",\n",
    "    },\n",
    "    \"Stress month\": {\n",
    "        \"paths\": _paths(\"stress/month.json\"),\n",
    "        \"template\": \"month\",\n",
    "        \"bundle\": \"perfect\",\n",
    "    },\n",
    "}\n",
    "\n",
    "comparison_df, comparison_unit_df = compare_history_profiles(\n",
    "    history_profiles, seed=300\n",
    ")\n",
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_side_by_side(df: pd.DataFrame, metric: str, *, figsize=(12, 5)):\n",
    "    pivot = df.pivot(index=\"rule\", columns=\"profile\", values=metric)\n",
    "    ax = pivot.plot(kind=\"bar\", figsize=figsize, title=f\"{metric.replace('_', ' ').title()} by profile\")\n",
    "    ax.set_ylabel(metric.replace(\"_\", \" \").title())\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "    return ax\n",
    "\n",
    "plot_side_by_side(comparison_df, \"average_response_minutes\")\n",
    "plot_side_by_side(comparison_df, \"coverage_ratio\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_side_by_side(comparison_df, \"utilization\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utilization_heatmap(comparison_unit_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips\n",
    "- Use `run_scenario(...)` presets to pick a rule bundle + history paths. Call `SCENARIO_LIBRARY.keys()` to list available presets.\n",
    "- Pass a subset of rule IDs to `run_scenario(..., rule_ids=[\"Rule_A\", \"Rule_Y\"])` to benchmark only a few policies.\n",
    "- To compare histories, add more `_paths(...)` entries that point to your incident-history JSON files. (See `resources/simulated_records/**/prompt.sh` for the generation commands/parameters.)\n",
    "- `unit_df` and `comparison_unit_df` can help spot bases or hotspots that spend a lot of time redeployed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
